---
title: "Financial Econometrics II"
author: "Matias Palmunen"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: united
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  fig.width = 10,
  fig.height = 6
)
```

## Introduction

This document contains analysis for Financial Econometrics II.

## Load Libraries

```{r load-libraries}
required_packages <- c(
  "tidyverse", "haven", "knitr", "kableExtra", "here",
  "ggplot2", "bacondecomp", "fixest", "did", "did2s", "didimputation"
)

new_packages <- required_packages[!(required_packages %in% 
                                    installed.packages()[, "Package"])]
if (length(new_packages)) {
  install.packages(new_packages, repos = "https://cloud.r-project.org")
}

invisible(lapply(required_packages, library, character.only = TRUE))
```


## Helper Functions

```{r helper-functions}
# Function to save figures for LaTeX with proper sizing
save_figure <- function(plot, filename, width = 6.5, height = 4) {
  # Ensure the figures directory exists
  fig_dir <- here::here("tex_report_2", "figures")
  if (!dir.exists(fig_dir)) {
    dir.create(fig_dir, recursive = TRUE)
  }
  
  # Construct the full path
  filepath <- file.path(fig_dir, filename)
  
  # Save the plot
  ggplot2::ggsave(
    filename = filepath,
    plot = plot,
    width = width,
    height = height,
    units = "in",
    dpi = 300,
    device = "pdf"
  )
  
  cat("Figure saved to:", filepath, "\n")
}

# Function to save tables in LaTeX tabular format
save_table <- function(data, filename, caption = "", label = "") {
  # Ensure the tables directory exists
  tables_dir <- here::here("tex_report_2", "tables")
  if (!dir.exists(tables_dir)) {
    dir.create(tables_dir, recursive = TRUE)
  }
  
  # Construct the full path
  filepath <- file.path(tables_dir, filename)
  
  # Convert to LaTeX table using kable
  latex_table <- kable(data, 
                       format = "latex", 
                       booktabs = TRUE,
                       caption = caption,
                       label = label)
  
  # Write to file
  writeLines(as.character(latex_table), filepath)
  
  cat("Table saved to:", filepath, "\n")
}
```

## Load Data

```{r load-data}
# Load data from the data folder
data_path <- here::here("data", "PS2_data.dta")
ps2_data <- read_dta(data_path) %>%
  as_tibble()

head(ps2_data)
```


## Problem (b): Event Study Graph

### Data Preparation

```{r data-prep}
# Load the data
data_path <- here::here("data", "PS2_data.dta")
ps2_data <- read_dta(data_path) %>%
  as_tibble()

# Examine the data structure
cat("Dataset dimensions:", nrow(ps2_data), "rows ×", ncol(ps2_data), "columns\n\n")

# Show first few rows
ps2_data %>%
  head(10) %>%
  kable(caption = "First 10 rows of PS2 data")

# Check for communities that experienced floods
flood_summary <- ps2_data %>%
  group_by(id_num) %>%
  summarize(
    num_floods = sum(hityear, na.rm = TRUE),
    flood_year = ifelse(any(hityear == 1), year[which(hityear == 1)[1]], NA)
  )

# Communities with exactly one flood
treated_communities <- flood_summary %>%
  filter(num_floods == 1)

# Never-treated communities
never_treated <- flood_summary %>%
  filter(num_floods == 0)

# Display summary statistics
tibble(
  Category = c("Communities with exactly 1 flood", "Never-treated communities", "Total communities"),
  Count = c(nrow(treated_communities), nrow(never_treated), nrow(flood_summary))
) %>%
  kable(caption = "Community Treatment Status Summary")
```

### Create Relative Time Variables

```{r create-relative-time}
# Create treatment year variable
ps2_data <- ps2_data %>%
  group_by(id_num) %>%
  mutate(
    treatment_year = ifelse(any(hityear == 1),
                           year[which(hityear == 1)[1]],
                           Inf),
    rel_time = year - treatment_year,
    post = as.numeric(year >= treatment_year),
    never_treated = is.infinite(treatment_year),
    ever_treated = !is.infinite(treatment_year)
  ) %>%
  ungroup() %>%
  mutate(
    state_year = interaction(state, year, drop = TRUE)
  )

# Drop units treated in the first period (no pre-treatment data)
t0 <- min(ps2_data$year, na.rm = TRUE)
ps2_data <- ps2_data %>%
  filter(is.infinite(treatment_year) | treatment_year > t0)

# Check distribution of treatment timing
treatment_timing <- ps2_data %>%
  filter(!is.infinite(treatment_year)) %>%
  distinct(id_num, treatment_year) %>%
  count(treatment_year) %>%
  rename(`Treatment Year` = treatment_year, `Number of Communities` = n)

# treatment_timing %>%
#   kable(caption = "Distribution of Treatment Timing")
support_tbl <- ps2_data %>%
  filter(is.finite(treatment_year)) %>%
  mutate(rel_time = year - treatment_year) %>%
  count(rel_time) %>%
  arrange(rel_time)
```

### Event Study Regression

Following Baker et al. (2022) recommendations on binning, I'll create binned endpoints for the event study.

- Use 6 bins to capture dynamics while avoiding sparse data issues, and also match Gallaghers 11 bins (with 11th being the aggregate). 11 bins might still be ok, but more than that, leads to quite sparse data at the tails. Importantly, the pre and post treatment patterns remain similar with 11 vs 6 bins.

- Keep the never treated communities as controls, 

- NB Gallagher runs the TWFE estimat using community, and state-by-year fixed effects. The specification in the problem sheet has communit and year fixed effects. 

   - In general I would choose to use state-by-year fixed effects. This is because there are likely to be many state-year level shocks (e.g. regulation changes affecting insurance) that are not absorbed by year fixed effects alone.

   - Using state-by-year fixed effects, identification then comes from variation between communities within the same state-year (i.e., comparing hit vs not-hit communities inside the same state and year).

   - However, to stay consistent with the problem sheet, and the fact that the Bacon decomposition by defualt doens't support year-by-state fixed effects, I will use community and year fixed effects here.

```{r rel-time-hist}
# To check the validity for binning
ps2_data %>%
  filter(is.finite(treatment_year)) %>%
  mutate(rel_time = year - treatment_year)%>%
  .$rel_time %>% hist()
```

```{r event-study-regression}
# Create relative time dummies with binning
# Binning strategy matches event_study_merged.R
ps2_data <- ps2_data %>%
  mutate(
    rel_time_binned = case_when(
      !ever_treated ~ 0,  # Never-treated units get 0 (will be absorbed by interaction)
      ever_treated & rel_time < -10 ~ -10,
      ever_treated & rel_time > 10 ~ 10,
      ever_treated ~ rel_time
    )
  )


# Event study regression with community and state-by-year fixed effects
# Using fixest with unit and state-by-year fixed effects
# Interaction with ever_treated uses never-treated units as control group
event_study_formula <- as.formula(paste(
  "ln_policies ~ ",
  paste0("i(rel_time_binned, ever_treated, ref = -1)"),
  " | id_num + state_year"
))

event_study_model <- feols(
  event_study_formula,
  data = ps2_data,
  cluster = ~ state  # Cluster by state as in Gallagher (2014)
)

# Display model summary
broom::tidy(event_study_model, conf.int = TRUE) %>%
  mutate(across(where(is.numeric), ~round(., 4))) %>%
  kable(caption = "Event Study Regression Results")

# Extract coefficients for plotting
event_study_coefs <- broom::tidy(
  event_study_model, conf.int = TRUE) %>%
  filter(grepl("rel_time", term)) %>%
  mutate(
    rel_time = as.numeric(gsub(".*::([-0-9]+).*", "\\1", term))
  ) %>%
  # Add the omitted period (-1) with coefficient 0
  bind_rows(
    tibble(
      term = "rel_time_binned::-1",
      estimate = 0,
      std.error = 0,
      statistic = NA,
      p.value = NA,
      conf.low = 0,
      conf.high = 0,
      rel_time = -1
    )
  ) %>%
  arrange(rel_time)
```

### Event Study Plot

```{r event-study-plot, fig.width=10, fig.height=6}
# Create event study plot
ggplot(event_study_coefs, aes(x = rel_time, y = estimate)) +
  geom_point(size = 3) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  geom_vline(xintercept = -0.5, linetype = "dotted", color = "blue") +
  labs(
    title = "Event Study: Effect of Floods on Log Insurance Policies per Capita",
    subtitle = "Gallagher (2014) replication",
    x = "Years Relative to Flood",
    y = "Coefficient Estimate",
    caption = "Note: Confidence intervals based on state-level clustering. \nPeriod -1 omitted as reference. Endpoints binned at -10 and +10  ."
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    plot.subtitle = element_text(size = 11),
    axis.title = element_text(size = 11)
  )
```

### Extended Event Study Plot (Binning at ±11)

- This binning matches with Gallagher (2014)

```{r event-study-regression-extended}
# Create relative time dummies with extended binning
# Bin at -11 and earlier, and +11 and later
ps2_data <- ps2_data %>%
  mutate(
    rel_time_binned_ext = case_when(
      !ever_treated ~ 0,  # Never-treated units get 0 (will be absorbed by interaction)
      ever_treated & rel_time <= -11 ~ -11,
      ever_treated & rel_time >= 11 ~ 11,
      ever_treated ~ rel_time
    )
  )

# Event study regression with extended time window
event_study_formula_ext <- as.formula(paste(
  "ln_policies ~ ",
  paste0("i(rel_time_binned_ext, ever_treated, ref = -1)"),
  " | id_num + state_year"
))

event_study_model_ext <- feols(
  event_study_formula_ext,
  data = ps2_data,
  cluster = ~ state
)

# Extract coefficients for plotting
event_study_coefs_ext <- broom::tidy(event_study_model_ext, conf.int = TRUE) %>%
  filter(grepl("rel_time_binned_ext", term)) %>%
  mutate(
    rel_time = as.numeric(gsub(".*::([-0-9]+).*", "\\1", term))
  ) %>%
  # Add the omitted period (-1) with coefficient 0
  bind_rows(
    tibble(
      term = "rel_time_binned_ext::-1",
      estimate = 0,
      std.error = 0,
      statistic = NA,
      p.value = NA,
      conf.low = 0,
      conf.high = 0,
      rel_time = -1
    )
  ) %>%
  arrange(rel_time)
```

```{r event-study-plot-extended, fig.width=10, fig.height=6}

# Create extended event study plot
ggplot(event_study_coefs_ext, aes(x = rel_time, y = estimate)) +
  geom_point(size = 3) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  geom_vline(xintercept = -0.5, linetype = "dotted", color = "blue") +
  labs(
    title = "Event Study: Effect of Floods on Log Insurance Policies per Capita (Extended Window)",
    subtitle = "Gallagher (2014) replication with extended time horizon",
    x = "Years Relative to Flood",
    y = "Coefficient Estimate",
    caption = "Note: Confidence intervals based on state-level clustering. \nPeriod -1 omitted as reference. Endpoints binned at -11 and +11."
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    plot.subtitle = element_text(size = 11),
    axis.title = element_text(size = 11)
  )
```



### (b)(i) Interpretation of Plotted Coefficients

The plotted coefficients represent the differential change in log flood insurance policies per capita for communities that experienced a flood relative to communities that did not, at each time period relative to the flood event.

Key interpretations:

1. **Pre-treatment coefficients (rel_time < 0)**: These should be close to zero and statistically insignificant if the parallel trends assumption holds. They test whether treated and control communities had similar trends before the flood.

2. **Post-treatment coefficients (rel_time >= 0)**: These capture the causal effect of experiencing a flood on insurance take-up. We expect positive coefficients if floods increase awareness and perceived risk.

3. **Dynamic effects**: The pattern across post-treatment periods shows how the effect evolves over time - whether it's immediate, grows, or fades.

4. **Magnitude**: Since the outcome is in logs, coefficients can be interpreted approximately as percentage changes (exact: exp(β) - 1).

### (b)(ii) Standard Error Clustering

```{r clustering-discussion}
# State-level clustering (Gallagher's choice)
model_state_cluster <- feols(
  event_study_formula,
  data = ps2_data,
  cluster = ~ state
)

# Community-level clustering
model_community_cluster <- feols(
  event_study_formula,
  data = ps2_data,
  cluster = ~ id_num
)

# Two-way clustering (state and year)
model_twoway_cluster <- feols(
  event_study_formula,
  data = ps2_data,
  cluster = ~ state + year
)

# Compare standard errors across different clustering approaches
clustering_comparison <- bind_rows(
  broom::tidy(model_state_cluster, conf.int = TRUE) %>% mutate(Clustering = "State"),
  broom::tidy(model_community_cluster, conf.int = TRUE) %>% mutate(Clustering = "Community"),
  broom::tidy(model_twoway_cluster, conf.int = TRUE) %>% mutate(Clustering = "State + Year")
)

clustering_comparison %>%
  select(Clustering, term, estimate, std.error, p.value) %>%
  mutate(across(c(estimate, std.error, p.value), ~round(., 4))) %>%
  filter(term != "(Intercept)") %>%
  head(15) %>%
  kable(caption = "Comparison of Standard Errors by Clustering Method (Selected Coefficients)",
        col.names = c("Clustering", "Term", "Estimate", "Std. Error", "P-value"))
```

### Visualization of Standard Error Differences

```{r clustering-visualization, fig.width=10, fig.height=8}

clustering_plot_data <- clustering_comparison %>%
  filter(grepl("rel_time", term)) %>%
  mutate(
    rel_time = as.numeric(gsub(".*::([-0-9]+).*", "\\1", term)),
    Clustering = factor(Clustering, levels = c("State", "Community", "State + Year"))
  ) %>%
  bind_rows(
    tibble(
      term = rep("rel_time_binned::-1", 3),
      estimate = rep(0, 3),
      std.error = rep(0, 3),
      conf.low = rep(0, 3),
      conf.high = rep(0, 3),
      rel_time = rep(-1, 3),
      Clustering = factor(c("State", "Community", "State + Year"), 
                         levels = c("State", "Community", "State + Year"))
    )
  ) %>%
  arrange(Clustering, rel_time)

# Plot 1: Confidence intervals comparison
# p1 <- ggplot(clustering_plot_data, aes(x = rel_time, y = estimate, color = Clustering)) +
#   geom_point(position = position_dodge(width = 0.3), size = 2) +
#   geom_errorbar(aes(ymin = conf.low, ymax = conf.high), 
#                 position = position_dodge(width = 0.3), 
#                 width = 0.2, alpha = 0.7) +
#   geom_hline(yintercept = 0, linetype = "dashed", color = "gray30") +
#   geom_vline(xintercept = -0.5, linetype = "dotted", color = "gray50") +
#   scale_color_manual(values = c("State" = "#E41A1C", 
#                                 "Community" = "#377EB8", 
#                                 "State + Year" = "#4DAF4A")) +
#   labs(
#     title = "Comparison of Confidence Intervals by Clustering Method",
#     subtitle = "Wider intervals indicate larger standard errors",
#     x = "Years Relative to Flood",
#     y = "Coefficient Estimate",
#     color = "Clustering"
#   ) +
#   theme_minimal() +
#   theme(
#     plot.title = element_text(face = "bold", size = 13),
#     legend.position = "bottom"
#   )

# Plot 2: Standard errors comparison
p2 <- clustering_plot_data %>%
  filter(rel_time != -1) %>%  # Omit reference period
  ggplot(aes(x = rel_time, y = std.error, color = Clustering, group = Clustering)) +
  geom_line(linewidth = 1) +
  geom_point(size = 2.5) +
  scale_color_manual(values = c("State" = "#E41A1C", 
                                "Community" = "#377EB8", 
                                "State + Year" = "#4DAF4A")) +
  labs(
    title = "Standard Errors by Clustering Method",
    subtitle = "Direct comparison of uncertainty across methods",
    x = "Years Relative to Flood",
    y = "Standard Error",
    color = "Clustering"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 13),
    legend.position = "bottom"
  )

# Display both plots
# print(p1)
print(p2)

# Summary statistics of standard errors by clustering method
clustering_plot_data %>%
  filter(rel_time != -1) %>%
  group_by(Clustering) %>%
  summarise(
    `Mean SE` = mean(std.error, na.rm = TRUE),
    `Median SE` = median(std.error, na.rm = TRUE),
    `Min SE` = min(std.error, na.rm = TRUE),
    `Max SE` = max(std.error, na.rm = TRUE)
  ) %>%
  mutate(across(where(is.numeric), ~round(., 4))) %>%
  kable(caption = "Summary Statistics of Standard Errors by Clustering Method")


```

**Comments on Clustering Choice:**

Gallagher (2014) clusters standard errors at the state level. This choice is appropriate because:

1. **Geographic correlation**: Flood experiences and insurance decisions may be correlated within states due to common regulations, insurance markets, and weather patterns.

2. **Treatment variation**: The treatment (floods) likely varies at a level between individual communities and states, so state-level clustering is conservative.

3. With panel data and treatment that varies at the state-year level, clustering at the state level accounts for serial correlation and within-state correlation.


**My assessment**: State-level clustering is appropriate and conservative. Alternative approaches could include:
- Two-way clustering (state and year) to account for common time shocks
- Community-level clustering if we believe communities are independent, but this would likely understate standard errors

However, remembering the general rule "cluster at least at the level of treatment variation"

I would make the same choice as Gallagher for the main results, but might show robustness to two-way clustering.

## Problem (c): Bacon-Goodman Decomposition

```{r bacon-decomposition}
# Prepare data for Bacon decomposition
# Need a binary treatment variable (ever treated)
# Include both treated and never-treated units
bacon_data <- ps2_data %>%
  mutate(
    treated = post
  )

# Make sure the panel is balanced, remove observations that don't appear in all periods
panel_structure <- bacon_data %>%
  group_by(id_num) %>%
  summarize(n_periods = n(), .groups = 'drop')
max_periods <- max(panel_structure$n_periods)
balanced_ids <- panel_structure %>%
  filter(n_periods == max_periods) %>%
  pull(id_num)

bacon_data_balanced <- bacon_data %>%
  filter(id_num %in% balanced_ids)

tibble(
  Metric = c("Original panel size", "Balanced panel size", "Number of units"),
  Value = c(nrow(bacon_data), nrow(bacon_data_balanced), length(balanced_ids))
) %>%
  kable(caption = "Panel Structure for Bacon Decomposition")


# Run Bacon, Note: very slow
# For computational feasibility, sample units if needed
set.seed(42)
if (length(balanced_ids) > 500) {
  sampled_ids <- sample(balanced_ids, 500)
  bacon_data_final <- bacon_data_balanced %>%
    filter(id_num %in% sampled_ids)
  cat("Sampling to", length(sampled_ids), "units for computational feasibility\n")
} else {
  bacon_data_final <- bacon_data_balanced
}

bacon_decomp <- bacon(
  ln_policies ~ treated,
  data = bacon_data_final,
  id_var = "id_num",
  time_var = "year"
)
```

```{r bacon-summary}

# Summarize decomposition
bacon_decomp %>%
  as_tibble() %>%
  group_by(type) %>%
  summarise(
    `N Comparisons` = n(),
    `Total Weight` = sum(weight),
    `Avg Estimate` = mean(estimate),
    .groups = 'drop'
  ) %>%
  mutate(across(where(is.numeric), ~round(., 4))) %>%
  kable(caption = "Bacon-Goodman Decomposition Summary")

bacon_summary <- bacon_decomp %>%
  group_by(type) %>%
  summarize(
    total_weight = sum(weight),
    avg_estimate = weighted.mean(estimate, weight),
    n_comparisons = n(),
    .groups = 'drop'
  )

print(bacon_summary)


```

```{r bacon plot}
# Visualize decomposition
ggplot(bacon_decomp, aes(x = weight, y = estimate, shape = type, color = type)) +
  geom_point(size = 3) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(
    title = "Bacon-Goodman Decomposition",
    subtitle = "Weights and estimates by comparison type",
    x = "Weight",
    y = "2x2 DiD Estimate",
    shape = "Comparison Type",
    color = "Comparison Type"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
```

### Interpretation of Bacon Decomposition


**Interpretation:**

The Bacon-Goodman decomposition reveals potential problems with the standard TWFE approach in staggered DiD settings:

1. **Forbidden comparisons**: The "later vs earlier" comparisons use already-treated units as controls, which is problematic if treatment effects are heterogeneous or time-varying.

2. **Weight on problematic comparisons**: The proportion of weight on late-to-early comparisons indicates how much the TWFE estimator relies on potentially biased comparisons.

3. **Direction of bias**: If treatment effects grow over time, the late-to-early ATT may be biased, potentially even having the wrong sign relative to the true effect.

Given the estimates and high weight on "Treated vs Untreated" expect the results to be quite robust. However, there is 



## Problem (d): Imputation Estimator by Hand

Following Borusyak et al. (2024), I'll implement the imputation estimator manually. In steps

1. Estimate fixed effects for community, year (this consistent with the earlier), not year-by-state
2. 

```{r temp}
ps2_data %>% filter(post == 0 )
```

```{r imputation-manual}
# Step 1: Estimate fixed effects using only untreated observations
# Untreated observations are those where post == 0 (not yet treated or never treated)

untreated_data <- ps2_data %>% filter(post == 0 )
fe_model_untreated <- feols(
  ln_policies ~ 1 | id_num + year,
  data = untreated_data
)

# Step 2: Extract fixed effects
unit_fes <- fixef(fe_model_untreated)$id_num
time_fes <- fixef(fe_model_untreated)$year

# Create data frames for merging
unit_fe_df <- tibble(
  id_num = as.numeric(names(unit_fes)),
  lambda_i = as.numeric(unit_fes)
)
time_fe_df <- tibble(
  year = as.numeric(names(time_fes)),
  gamma_t = as.numeric(time_fes)
)

# Step 3: For treated observations, impute counterfactual Y(0)
ps2_data_impute <- ps2_data %>%
  left_join(unit_fe_df, by = "id_num") %>%
  left_join(time_fe_df, by = "year") %>%
  mutate(
    Y_hat_0 = lambda_i + gamma_t,
    tau_hat = ifelse(post == 1,
                     ln_policies - Y_hat_0,
                     NA_real_)
  )

ps2_data_impute %>%
  filter(!is.na(tau_hat)) %>%
  summarise(
    N = n(),
    Mean = mean(tau_hat),
    Median = median(tau_hat),
    SD = sd(tau_hat),
    Min = min(tau_hat),
    Max = max(tau_hat)
  ) %>%
  mutate(across(where(is.numeric) & !N, ~round(., 4))) %>%
  kable(caption = "Summary Statistics of Imputed Treatment Effects (τ̂)")
```

### Event Study Plot with Imputation Estimator

To create the event study plot calculate the $\tua$ for all observations (not just treated)

```{r imputation-event-study}
imputation_event_data <- ps2_data_impute %>%
  filter(!is.infinite(treatment_year)) %>%
  mutate(
    tau_hat_all = ln_policies - Y_hat_0,
    rel_time_binned = case_when(
      rel_time <= -10 ~ -10,
      rel_time >= 10 ~ 10,
      TRUE ~ rel_time
    )
  ) %>%
  filter(!is.na(tau_hat_all) & !is.na(rel_time_binned))

rel_time_values <- sort(unique(imputation_event_data$rel_time_binned))
rel_time_values <- rel_time_values[rel_time_values != -1]

imputation_coefs <- map_dfr(rel_time_values, function(t) {
  data_t <- imputation_event_data %>%
    mutate(treat_t = as.numeric(rel_time_binned == t))
  
  model <- lm(tau_hat_all ~ treat_t, data = data_t)
  
  broom::tidy(model, conf.int = TRUE) %>%
    filter(term == "treat_t") %>%
    mutate(rel_time = t)
}) %>%
  bind_rows(
    tibble(
      term = "treat_t",
      estimate = 0,
      std.error = 0,
      statistic = NA,
      p.value = NA,
      conf.low = 0,
      conf.high = 0,
      rel_time = -1
    )
  ) %>%
  arrange(rel_time)
```

```{r imputation-event-study-plot, fig.width=10, fig.height=6}

ggplot(imputation_coefs, aes(x = rel_time, y = estimate)) +
  geom_point(size = 3, color = "darkblue") +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high),
                width = 0.2, color = "darkblue") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  geom_vline(xintercept = -0.5, linetype = "dotted", color = "blue") +
  labs(
    title = "Event Study: Imputation Estimator (Manual Implementation)",
    subtitle = "Following Borusyak et al. (2024)",
    x = "Years Relative to Flood",
    y = "Treatment Effect Estimate",
    caption = "Note: Counterfactuals estimated from never-treated and not-yet-treated units only.\nPeriod -1 omitted as reference. Endpoints binned at -6 and +6."
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    plot.subtitle = element_text(size = 11),
    axis.title = element_text(size = 11)
  )

```


**Interpretation:**

The imputation estimator avoids using already-treated units as controls. The event study plot shows:

1. **Pre-treatment effects**: Should be centered around zero (by construction, since we're using the untreated sample to estimate the counterfactual)

2. **Post-treatment effects**: Show the causal impact of floods on insurance take-up

3. **Comparison to TWFE**: Differences from the standard TWFE event study indicate bias from forbidden comparisons

## Problem (e): ATT Estimation and Comparison

### Manual ATT Estimation

```{r att-manual}
# Estimate ATT as simple average of tau_hat for treated observations
att_manual <- ps2_data_impute %>%
  filter(!is.na(tau_hat)) %>%
  summarize(
    ATT = mean(tau_hat),
    SE_incorrect = sd(tau_hat) / sqrt(n()),
    n_treated = n()
  )

# Display manual ATT results
att_manual %>%
  mutate(
    Method = "Manual (Average of τ̂)",
    `ATT Estimate` = round(ATT, 4),
    `SE (Incorrect)` = round(SE_incorrect, 4),
    `N Treated Obs` = n_treated
  ) %>%
  select(Method, `ATT Estimate`, `SE (Incorrect)`, `N Treated Obs`) %>%
  kable(caption = "Manual ATT Estimation Results")

# Alternative: regress tau_hat on treatment indicator (should give same result)
att_regression <- lm(tau_hat ~ 1, data = ps2_data_impute %>% filter(!is.na(tau_hat)))
```

### ATT Using did_imputation Package

```{r att-package-didimputation}
did_imputation_data <- ps2_data %>%
  filter(!is.infinite(treatment_year))

dimp_result <- did_imputation(
  data = did_imputation_data,
  yname = "ln_policies",
  gname = "treatment_year",
  tname = "year",
  idname = "id_num",
  first_stage = ~ 0 | id_num + year,
  cluster_var = "state"
)

dimp_result %>%
  as.data.frame() %>%
  mutate(across(where(is.numeric), ~round(., 4))) %>%
  kable(caption = "did_imputation Package Results (Borusyak et al. 2024)")

att_dimp <- mean(dimp_result$estimate, na.rm = TRUE)
se_dimp <- mean(dimp_result$std.error, na.rm = TRUE)

cat("\n")
```

### Event Study Plot with did_imputation

```{r didimputation-event-study, fig.width=10, fig.height=6}
dimp_es_data <- ps2_data %>%
  filter(!is.infinite(treatment_year))

dimp_es_result <- did_imputation(
  data = dimp_es_data,
  yname = "ln_policies",
  gname = "treatment_year",
  tname = "year",
  idname = "id_num",
  first_stage = ~ 0 | id_num + year,
  horizon = TRUE,
  pretrends = TRUE,
  cluster_var = "state"
)

dimp_es_coefs <- dimp_es_result %>%
  as.data.frame() %>%
  filter(!is.na(term)) %>%
  mutate(
    rel_time = as.numeric(gsub(".*[^0-9-]([0-9-]+)$", "\\1", term)),
    conf.low = estimate - 1.96 * std.error,
    conf.high = estimate + 1.96 * std.error
  ) %>%
  arrange(rel_time)

ggplot(dimp_es_coefs, aes(x = rel_time, y = estimate)) +
  geom_point(size = 3, color = "purple") +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), 
                width = 0.2, color = "purple") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  geom_vline(xintercept = -0.5, linetype = "dotted", color = "blue") +
  labs(
    title = "Event Study: did_imputation Estimator (Borusyak et al. 2024)",
    subtitle = "Imputation-based difference-in-differences",
    x = "Years Relative to Flood",
    y = "Treatment Effect Estimate",
    caption = "Note: Estimates from did_imputation package with state-level clustering.\nReference period at -1."
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    plot.subtitle = element_text(size = 11),
    axis.title = element_text(size = 11)
  )
```

### Comparison and Discussion

```{r comparison}
# Create comprehensive comparison table
tibble(
  Method = c("Manual Implementation", "Package (did2s)", "Package (did_imputation)"),
  `ATT Estimate` = c(att_manual$ATT, att_package, att_dimp),
  `Standard Error` = c(att_manual$SE_incorrect, se_package, se_dimp),
  `SE Note` = c("Incorrect (naive)", "Correct (clustered)", "Correct (clustered)")
) %>%
  mutate(across(where(is.numeric), ~round(., 4))) %>%
  kable(caption = "Comparison of ATT Estimates") %>%
  footnote(general = "did2s: Gardner (2021); did_imputation: Borusyak et al. (2024)")

# Additional diagnostics
tibble(
  Metric = c("Absolute difference in ATT estimates", "SE ratio (manual/package)"),
  Value = c(
    round(abs(att_manual$ATT - att_package), 4),
    round(att_manual$SE_incorrect / se_package, 2)
  )
) %>%
  kable(caption = "Estimation Diagnostics")
```

**Discussion:**

1. **Do we get the same ATT estimate?**
   - The ATT estimates should be very similar across all three implementations (potentially with small numerical differences due to implementation details)
   - The manual implementation, did2s (Gardner 2021), and did_imputation (Borusyak et al. 2024) all use similar underlying logic: estimate counterfactuals from untreated units
   - did2s and did_imputation are both modern estimators that avoid the "forbidden comparisons" problem in staggered DiD settings

2. **Why are the manual standard errors incorrect?**

   The manual approach (simply taking sd(τ̂)/√n) is incorrect because:

   a) **Estimation uncertainty**: We're using *estimated* fixed effects (λ̂ᵢ, γ̂ₜ) rather than true values. The simple formula doesn't account for uncertainty in these first-stage estimates.

   b) **Correlation structure**: Treatment effects τ̂ᵢₜ are not independent - they share common estimated fixed effects, inducing correlation.

   c) **Clustering**: The package correctly accounts for clustering (at state level), which the manual SE ignores.

   The package uses proper asymptotic theory or bootstrap methods to compute standard errors that account for the two-stage estimation procedure.

## Results Summary

### Key Findings

1. **Event Study (TWFE)**: [Describe pattern of coefficients - pre-trends, post-treatment effects]

2. **Bacon Decomposition**: [Summarize weights on different comparison types and potential for bias]

3. **Imputation Estimator**: [Compare results to TWFE, discuss robustness]

4. **ATT Estimates**: [Report final estimates with correct standard errors]

## Conclusion

This analysis demonstrates the application of modern difference-in-differences methods to study the effect of flood experience on insurance take-up. Key methodological insights:

1. **Staggered DiD complications**: The Bacon decomposition reveals how TWFE estimators can be biased when treatment timing varies and effects are heterogeneous.

2. **Imputation methods**: Newer estimators like Borusyak et al. (2024) avoid problematic comparisons by only using not-yet-treated units as controls.

3. **Inference**: Proper standard errors must account for the two-stage estimation procedure and clustering structure.

4. **Practical importance**: In this application, [discuss whether standard and robust methods give similar or different conclusions].
